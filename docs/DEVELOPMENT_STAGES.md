# DEVELOPMENT_STAGES — план развития до «идеальной библиотеки» (RU)

В ближайших задачах (ядро):
- UNK/NE защита: помечать неизвестные токены (UNK) и именованные сущности (NE), не изменять их в Grammar/WordOrder/PostProcessing; копировать «как есть» или транслитерировать по целевому языку; отражать в метриках и layerResults.
- Понижение confidence: вычислять долю unknown-спанов и понижать итоговый confidence; выводить список UNK-спанов в результат.
- User feedback loop: логировать unknown в user_data, поддержать быстрый user-dictionary с приоритетом над общим, горячая загрузка без перезапуска.
- Контекстная дисамбигуация: для полисемии (go) добавить коллокационные/фрейм‑правила и скоринг (preposition frame, POS‑окрестность, domain), alternatives[] и trace.
- Масштаб правил: уйти от «N×M» в пользу классов/шаблонов правил (POS‑биграммы, фреймы, паттерны коллокаций), индексировать trigram/phrasal patterns, Aho‑Corasick для фраз, ограничивать окно матчинга; кеши и шардинг.
- CLI validate+metrics: счётчики UNK, доля покрытых токенов, применённые классы правил.

Ниже — прагматичный план (по этапам) работ, которые ещё предстоит выполнить для выхода на уровень «идеальной библиотеки». Формат вдохновлён чек-листом DEVELOPMENT_STAGES.

## Спецификация: что реализовать для «нормальной» работы ядра

1) Данные словаря (Dictionary) — расширение модели
- Обязательные: id, language_pair, source_word (lemma), target_word, part_of_speech, created_at, updated_at
- Рекомендуемые: sense_id, definition (кратко), domains (it, travel, general…), examples[], synonyms[], priority/rank, default_sense (bool)
- Bootstrap частоты (если нет корпусов):
  - Нормализация внутри headword: упорядочить варианты (ladder) и раздать buckets (напр. [80,60,50,40,30])
  - Тай-брейк детерминированный: небольшой стабильный offset по hash(source+target)
  - При наличии монолингвальных частот: freq = mix(src,tgt) после нормализации; иначе — buckets по ladder
- User-словарь: отдельное хранилище с приоритетом над общим; горячая перезагрузка

2) Контекст и дисамбигуация (без корпусов)
- POS/лемматизация (лёгкие):
  - Токенизация + лексикон частотных слов + суффиксные правила; для en/ru — базовый набор
  - Лемматизация упрощённая (правила для глаголов/существительных)
- Окно контекста: [-2..+2]; признаки: prev/next lemma, POS, препозиции/частицы, пунктуация
- Микрофреймы/коллокации (20–50 правил на язык-пару):
  - verb+prep: go to/into/by/for … → набор классов смысла
  - V+V-ing, det/aux шаблоны, простые объектные классы (transport/place/time/activity/human)
- Сигнатура/кэш:
  - signature = (head_lemma, prep, obj_class, prev_pos, next_pos)
  - Memo LRU+TTL на выбор варианта; стабильный тай-брейк по hash(signature)
- Скоринг (без «частот»):
  - score = w_frame + w_colloc + w_pos + w_default
  - При равенстве → тай-брейк по hash; default_sense — безопасный выбор

3) UNK/NE защита (неизвестные/имена)
- Детекторы: капитализация, скрипт, цифры/символы, URL/email, CamelCase, словарная неизвестность
- Поведение: копировать «как есть» или транслитерировать; пометить спан как protected
- Слои Grammar/WordOrder/PostProcessing не модифицируют protected-спаны
- Метрики: количество UNK, доля текста, список спанов в layerResults; понижение confidence пропорционально доле UNK
- Логирование в user_data; wizard для быстрой фиксации в user-словаре

4) Детерминизм выбора
- Запрет RNG; все решения стабильные при одинаковом контексте
- Тай-брейк по hash(signature) и фиксированным seed’ам вариантов
- Memo-результаты для одинаковых запросов в пределах TTL

5) Масштабирование правил (без взрыва данных)
- Классы/шаблоны вместо «N×M»: POS-биграммы, фреймы, коллокации по объект‑классам
- Индексация: Aho‑Corasick для фраз; ограничение окна матчинга; префильтрация по POS
- Хранение: шардирование JSONL по префиксу/категории; manifest.json с sha256/версией; atomic tmp+rename

6) Инструменты и метрики
- Метрики ядра: coverage (фразы/слова/UNK), распределение слоёв, latency, кэш hit‑rate, rule_hits по классам
- CLI/SDK‑hooks: validate данных (схема/пустые поля), snapshot метрик, экспорт/импорт user‑словаря
- Тест‑план: e2e на микрофреймы, UNK‑защиту, детерминизм (одинаковый ввод→одинаковый вывод), деградацию

7) Поведение по умолчанию (fallback)
- Порядок: Phrase > (Frames/Collocations) > Dictionary > DefaultSense > Copy/Translit (UNK)
- Если несколько равносильных вариантов — выбираем default_sense; альтернативы → alternatives[]
- Слои не «ломают» защищённые спаны; PostProcessing лишь косметика пробелов/пунктуации вне protected

8) План внедрения (минимально жизнеспособные шаги)
- v0: default_sense в словаре + детерминированный тай‑брейк + memo‑кэш
- v1: UNK/NE и protected‑спаны + понижение confidence
- v2: микрофреймы (verb+prep, V+V‑ing) и объект‑классы с 30–50 правилами; подключить скоринг
- v3: метрики coverage/UNK/rule_hits; простые инструменты валидации
- v4: POS/леммы light + расширение фреймов; шардирование правил
- v5: user‑feedback (дообучение offline) и hot‑reload user‑словаря


















Статус: [x]

Этап 0 — Базовая стабильность 
- [x] Перевод data layer на JSONL-хранилище
- [x] Обновление репозиториев и кэша
- [x] Переписывание тестов под новый бэкенд
- [x] Минимальная документация и примеры

Этап 1 — Стабилизация публичного API (in progress)
- [ ] Пройтись по публичным классам/методам и зафиксировать API (semver)
- [ ] Обозначить «стабильные» и «экспериментальные» части API
- [ ] Добавить подробные док-комментарии ко всем публичным API
- [ ] Подготовить public examples (example/main.dart) и обновить README (Quick start, Variant A)
- [ ] Обновить CHANGELOG на английском и стандартизировать формат

Этап 2 — Инструменты данных и валидация
- [ ] Усилить импорт (CSV/JSON/JSONL): отчёт об ошибках, пропуски, статистика
- [ ] Валидатор данных и схемы (форматы строк, допустимые пары языков)
- [ ] CLI: консистентные команды (db/import/export/validate) + примеры использования

Этап 3 — Производительность и память
- [ ] Профилирование горячих путей (поиск слов/фраз, кэширование)
- [ ] Оптимизация in-memory индексов и политики кэша (LRU/TTL/разделение по языкам)
- [ ] Бенчмарки под реальную нагрузку и регрессионные перф-тесты

Этап 4 — Документация и примеры
- [ ] Дополнить usage_en.md/usage_ru.md примерами для Flutter (path_provider, init в виджете)
- [ ] Добавить разделы «FAQ» и «Troubleshooting»
- [ ] Сформировать «Cookbook» (частые сценарии: импорт данных, тонкая настройка кэша, отладка)

Этап 5 — Качество, CI/CD
- [ ] GitHub Actions: форматирование, анализ, юнит/интеграционные тесты, кэш пакетов
- [ ] Матрица CI (Windows/macOS/Linux, stable/beta SDK)
- [ ] codecov/coverage отчёт, пороги качества

Этап 6 — Экосистема и интеграции
- [ ] Виджет(ы) для Flutter (простая интеграция движка в UI)
- [ ] Адаптеры для внешних источников данных (кастомные форматы/эндпоинты)
- [ ] Расширяемость слоёв pipeline (плагины слоёв, интроспекция, метрики)

Этап 7 — Дополнительные возможности
- [ ] Морфология/лемматизация для ряда языков
- [ ] Fuzzy-поиск, подсказки и автодополнение
- [ ] Транслитерация/нормализация ввода

Релизы и управление версиями
- [ ] Принять политику версионирования с «десятичными шагами» (например, 0.0.11)
- [ ] Чёткие release notes для каждого релиза
- [ ] Скрипт/джоб для автоматизации «tag -> publish» (при ручном подтверждении)

Критерии «идеальной библиотеки» (Definition of Done)
- Полностью документированный и стабильный публичный API
- Репозиторий с чистым CI/CD, воспроизводимые сборки и тесты зелёные
- Производительность подтверждена бенчмарками, предсказуемое потребление памяти
- Удобные инструменты работы с данными (CLI+импорт/валидация)
- Понятные примеры интеграции с Flutter и Dart CLI
- План развития и прозрачные релизы
